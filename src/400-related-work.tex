% !TEX root = document.tex

\chapter{\label{chap:related-work}Related Work and Discussion}
In this chapter we will look at some of the theory behind the compilation scheme used in this thesis and discuss the shortcomings and improvements of our proposed command tree solution.

\section{\label{section:opmonad}The Operational Monad}
In this section we will derive the command tree monad. We follow the style of the paper \citetitle{DBLP:conf/haskell/KiselyovI15} \autocite{DBLP:conf/haskell/KiselyovI15}, which gives a derivation of the freer monad, a close relative of the command tree. The main problem the command tree and its relatives address is: expressing side-effectful computation in a composable/modular manner. We will start by unpacking this definition.

A side-effect can be understood as an interaction of an expression with its context \autocite{DBLP:conf/tacs/CartwrightF94}. A concrete example is the communication between a number of clients and a central server. A side-effect is a request from a client to the server. This can be a request for some data or an action. From this it follows immediately that we can model side effects with data types that specify such a request. A trivial example is a ping request.

\begin{lstlisting}[language=Haskell]
data Request = Ping
\end{lstlisting}

The result of the ping request may be used in another part of the program. Our \icode{Request} data type does not indicate what the return type of a ping request will be. Moreover, there is no place where the reply of the request is bound. We can define a data type that helps us with both these problems. We will call it \icode{Compute}.

\begin{lstlisting}[language=Haskell]
data Compute = Done Int | Compute Request (Int -> Compute)
\end{lstlisting}

\icode{Compute} has two constructors that have the same role as those of the command tree. The \icode{Done} constructor represents a computation without side effects that returns an integer. \icode{Compute} binds \icode{Request}s together. The result of a request is an integer and may be used in the following computations. An example shows the data types in action. We send two sequential ping requests to the central server and bind them to the variables \icode{i} and \icode{j}. Finally, we return the average of both. How a ping request is actually implemented is left open. \icode{Request} just provides the interface for effectful computation.

\begin{lstlisting}[language=Haskell]
pingtwiceavg = Compute Ping (\ i -> Compute Ping (\ j -> Done ((i + j) `div` 2)))
\end{lstlisting}

This way of defining sequences of effectful computations is called operational \autocite{operationalmonad}. It is an alternative to other monadic implementations of side-effects. The upside of operational monads is their compositional nature. Traditional implementation of side-effects such as monad transformers \autocite{DBLP:conf/popl/LiangHJ95} also compose, but suffer from non-commutative behavior \autocite{DBLP:conf/ifl/DayH13}.

Haskell provides typeclasses for defining monads. These are similar to an interface. Our \icode{Compute} data type does not qualify for these, because Haskell requires monads to be parameterized over a type. We define our own \icode{bind} function, which composes two computations; the \icode{unit} function creates a trivial computation. In the implementation of the \icode{bind} function we see that it pushes a function from an integer to a computation into the continuation of a computation. This is similar to list concatenation.

\begin{lstlisting}[language=Haskell]
bind (Done i)      f = f i
bind (Compute r k) f = Compute r (\ i -> bind (k i) f)
-- unit is trivial
unit = Done
\end{lstlisting}

With our monadic definitions in place we can create a pretty version of our previous program that takes the average ping. We will define a helper function that represent a program that sends a ping request and returns the result. This enables us to \icode{bind} these smaller programs together.

\begin{lstlisting}[language=Haskell]
ping = Compute Ping Done

prettyping =
  ping `bind` \ i ->
  ping `bind` \ j ->
  unit ((i + j) `div` 2)
\end{lstlisting}

If we substitute our requests for commands and add subcontinuations to \icode{Compute} we obtain our command tree. In the next subsection we will derive command trees in another way with the free monad.

\subsection{\label{subsection:freemonad}Free Monad}
Both the command tree and the \icode{Compute} data type are a specialization of the free monad \autocite{swierstra2008data}. The free monad arises naturally when composing functors. In mathematical terms a functor is a mapping between categories \autocite{barr1990category}. In practical terms a functor is something that can mapped over. A list is an example of a functor. We will take as example functor a modified version of the \icode{Maybe} data type and show what happens when we compose it with itself \autocite{freemonadsforall}. It describes a programming language where we either \icode{Stop} with execution or sound a \icode{Bell} and continue.

\begin{lstlisting}[language=Haskell]
data Program a = Stop | Bell a

p0 :: Program (Program a)
p0 = Bell Stop

p1 :: Program (Program (Program a))
p1 = Bell (Bell Stop)
\end{lstlisting}

We see that our type grows with our expression. Both \icode{p0} and \icode{p1} should have the type \icode{Program a}. We want a function of type \icode{Program (Program a) -> Program a} that removes the nesting of functors. What we need is a fixpoint of a functor.

\begin{lstlisting}[language=Haskell]
data Fix f where
  Fix :: f (Fix f) -> Fix f
\end{lstlisting}

The type of \icode{Fix} reflects the type of the function that we wanted. Our new programs will be of type \icode{Fix Program}.

\begin{lstlisting}[language=Haskell]
fp0 :: Fix Program
fp0 = Fix (Bell (Fix Stop))

fp1 :: Fix Program
fp1 = Fix (Bell (Fix (Bell (Fix Stop))))
\end{lstlisting}

\icode{Fix} is almost a monad. What we need is a generic way to terminate programs. We will also need to parameterize over the return type instead of a functor. This leads us to the free monad.

\begin{lstlisting}[language=Haskell]
data Free f a where
  Pure   :: a            -> Free f a
  Impure :: f (Free f a) -> Free f a
\end{lstlisting}

The free monad is thus a way to nest a functor, while maintaining a basic type of that functor. The free monad is restricted by this functor requirement. Without it, it is not a monad. Command trees do not have this requirement. We use a wrapper for our commands that ensures they are functors. This wrapper is a complex functor, but the principle is based on a simpler concept: pretending a mapping happened. The data type that captures this notion is the functor by construction \icode{F}. It consists of something resembling a functor and a mapping over the contents of this fake functor. Whenever we map over \icode{F}, we simply compose with the second argument. We pretend something happened; we update our mapping function.

\begin{lstlisting}[language=Haskell]
data F f a where
  F :: f a -> (a -> b) -> F f b

instance Functor (F f) where
  fmap g (F f h) = F f (g . h)
\end{lstlisting}

If we extend this idea to the free monad we obtain the freer monad. The functor the command trees in this thesis use is of a more specialized nature related to \icode{Cps} and \icode{Val}.

\begin{lstlisting}[language=Haskell]
data G f a where
  G :: f -> [Val] -> (Val -> b) -> G f b

instance Functor (G f) where
  fmap g (G f ks k) = G f ks (g . k)
\end{lstlisting}

Command trees can thus also be derived from the free monad which itself arises when we nest functors. In this and the previous subsection we have shown that command trees arise when we want to model requests or nest functors. This corresponds nicely to the objectives of modular denotational semantics where we work with semantic language modules that may have effects.

\section{\label{section:denotationalsemantics}Modular Denotational Semantics}
In this section we will give a short introduction to modular denotational semantics and then show how it relates to the work on the LamToWat compiler in this thesis. We will begin by stating some definitions. Denotational semantics is a method of giving meaning to programs by constructing mathematical objects which we often call 'values'. A programming language consists of multiple interacting parts called 'terms', like a function module or an arithmetic module. Terms can be given corresponding values separately. Then the meaning of the combined modules which make up a language is simply the sum or composition of these mappings. Originally there have been two popular approaches to solving this problem: algebraic effects \cite{DBLP:conf/tacs/CartwrightF94} and monad transformers \cite{DBLP:conf/popl/LiangHJ95}. To give meaning to a program we write a program called an 'interpreter' that maps terms in each module to their respective denotation.

A denotational semantics is made up of three things: terms, values, and effects. We represent all three with Haskell constructs. A semantics is modular when are able to split and extend all three components. In Haskell open unions give us the power to do this for terms and values. To model effects we will need monads: either monad transformers or the free monad depending on which approach we choose. They arise as a solution to the unstable denotation problem.

% SEE: temp.hs in LamToWat
% example: unstable....
% TODO (blog post?) -- show connection via type classes
Now we will give a n example of a modular denotational semantics for the \icode{Lam} language we are already familiar with. We will illustrate the relation between monad transformers and algebraic effects \cite{DBLP:conf/haskell/SchrijversPWJ19}. One can be translated into the other and vice-versa. Both approaches allow one to construct an interpreter for \icode{Lam}. We will use Haskell typeclasses to highlight the relation by providing instances either.

% why did we use denotational semantics to write a compiler?
Denotational semantics are very useful because it leads to a method of proving equality of terms of a language. When two terms have the same denotational value, they have the same meaning and one can be replaced by the other. This gives rise to many optimizations, which are provably correct.

One of the goals of a compiler is to optimize code, thus one can see where denotational semantics comes in. Moreover, it is important that the meaning of a program is not changed during compilation. In this thesis we have tried to extend this concept of denotational semantics from interpreters to compilers. In the first version of the compiler we used the approach of monad transformers. In the second version we used algebraic effects represented by command trees.

\section{\label{section:cps}Continuation-passing Style}

% why did we choose cps as baseline and why did we use cps based commmand tree
% blog post?

\section{\label{section:commandtrees}Command Tree Improvements}
% intro
Although command trees provide a useful abstraction for language implementers, it does require knowledge of the block model for control flow. In the original version of LamToWat CPS conversion is implemented using a metacontinuation. This metacontinuation indicates what a program does next. When we transform a application we have to construct a return point function and pass it as the last argument to the new application. These manipulations of control flow become even more non-trivial when implementing imperative language constructs such as \icode{while} and \icode{for}. Moreover, when we have to use multiple metacontinuations in case we want to throw exceptions or break from a \icode{while} loop, the bookkeeping of metacontinuations becomes cumbersome. Command trees help the programmer somewhat by having these metacontinuations live inside the tree. The language implementer will still need to wrap certain parts of code inside a block and fetch the right continuation at the right point. The real burden is now put on the compiler writer, who has to compile the command tree. This requires juggling of the internalized metacontinuations and though it may be simpler than the alternative, it is not simple in itself.

Command trees are very similar to \icode{Cps} and can even be replaced by them. The added value of command trees is better pattern matching and more flexibility in the commands it uses. However, in the LamToWat implementation we choose commands that match \icode{Cps} almost one-to-one. The IR transformations remain mostly the same. One could argue that the command trees should be compiled to \icode{Cps} instead, allowing for reuse of the original compiler code. This could provide an improved front-end of the compiler with a \icode{Cps} based back-end.

% discuss original command tree and problems with types
Command trees originally had more types, but these proved to make compilation more difficult. The goal was to make the transformations type-preserving, meaning that if a program has a type before the transformation then the transformed program has a matching transformed type. In concrete terms it means that if you write a well-typed program and compile it, the compiled program will also be well-typed. The compiler writer will have to define the transformations on both the data type itself and its type. In addition, the programmer will have to prove to the typechecker that the transformed expression has the correct type. 

These added requirements on behalf of the compiler writer make the actual implementation very hard. This could partly be a attributed to the type system of the metalanguage (Haskell), which does not have 'real' dependent types. It is for example not trivial to prove that if you concatenate a \icode{Vec n a} and a \icode{Vec m a} the resulting type will be \icode{Vec (m + n) a)} \autocite{10.1145/2578854.2503786}. Typing the transformations of CPS is not a new problem and has been solved by a multiple authors \autocite{DBLP:conf/popl/MorrisettWCG98, DBLP:conf/haskell/GuillemetteM07, DBLP:conf/pldi/Chlipala07}. Keeping these transformation both type-preserving and easy to write in a real metalanguage is more complicated.
